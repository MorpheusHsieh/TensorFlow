{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XWb:\n",
      "[[-0.35999998  0.28      ]]\n",
      "y:\n",
      "[[0.   0.28]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.Variable([[0.4, 0.2, 0.4]])\n",
    "\n",
    "W = tf.Variable([[-0.5, -0.2],\n",
    "                 [-0.3,  0.4],\n",
    "                 [-0.5,  0.2]])\n",
    "\n",
    "b = tf.Variable([[0.1, 0.2]])\n",
    "\n",
    "XWb = tf.matmul(X,W) + b\n",
    "y = tf.nn.relu(XWb)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print('XWb:'); print(sess.run(XWb))\n",
    "    print('y:');   print(sess.run(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XWb:\n",
      "[[-0.35999998  0.28      ]]\n",
      "y:\n",
      "[[0.41095957 0.5695462 ]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.Variable([[0.4, 0.2, 0.4]])\n",
    "\n",
    "W = tf.Variable([[-0.5, -0.2],\n",
    "                 [-0.3,  0.4],\n",
    "                 [-0.5,  0.2]])\n",
    "\n",
    "b = tf.Variable([[0.1, 0.2]])\n",
    "\n",
    "XWb = tf.matmul(X,W) + b\n",
    "y = tf.nn.sigmoid(XWb)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print('XWb:')\n",
    "    print(sess.run(XWb))\n",
    "    print('y:')\n",
    "    print(sess.run(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b:\n",
      "[[-1.6107776  1.2792151]]\n",
      "W:\n",
      "[[ 1.6928875   1.0464482 ]\n",
      " [ 0.6647383   0.25211555]\n",
      " [-0.1522005   0.2852696 ]]\n",
      "y:\n",
      "[[0.        1.8623254]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.Variable([[0.4, 0.2, 0.4]])\n",
    "W = tf.Variable(tf.random_normal([3, 2]))\n",
    "b = tf.Variable(tf.random_normal([1, 2]))\n",
    "\n",
    "XWb = tf.matmul(X,W) + b\n",
    "y = tf.nn.relu(XWb)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print('b:'); print(sess.run(b))\n",
    "    print('W:'); print(sess.run(W))\n",
    "    print('y:'); print(sess.run(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b:\n",
      "[[ 0.3926433 -1.5605307]]\n",
      "W:\n",
      "[[-0.3007607   0.33960956]\n",
      " [-0.4758405   0.46838334]\n",
      " [-0.32711554 -0.49152502]]\n",
      "y:\n",
      "[[0.0463247 0.       ]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.Variable([[0.4, 0.2, 0.4]])\n",
    "W = tf.Variable(tf.random_normal([3, 2]))\n",
    "b = tf.Variable(tf.random_normal([1, 2]))\n",
    "\n",
    "XWb = tf.matmul(X,W) + b\n",
    "y = tf.nn.relu(XWb)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    (_b, _W, _y) = sess.run((b, W, y))\n",
    "    print('b:'); print(_b)\n",
    "    print('W:'); print(_W)\n",
    "    print('y:'); print(_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.2769206  -1.220772    0.69739133 -0.3548067  -0.47721592]\n"
     ]
    }
   ],
   "source": [
    "ts_norm = tf.random_normal([1000])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    norm_data = ts_norm.eval()\n",
    "print(norm_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(norm_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b:\n",
      "[[-2.8109574 -1.0096067]]\n",
      "W:\n",
      "[[-1.846255   3.8804002]\n",
      " [-0.985027  -0.9680935]\n",
      " [-1.8848157 -1.5056747]]\n",
      "X:\n",
      "[[0.4 0.2 0.4]]\n",
      "y:\n",
      "[[0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(tf.random_normal([3, 2]))\n",
    "b = tf.Variable(tf.random_normal([1, 2]))\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 3])\n",
    "\n",
    "XWb = tf.matmul(X,W) + b\n",
    "y = tf.nn.relu(XWb)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    X_ary = np.array([[0.4, 0.2, 0.4]])\n",
    "    (_b, _W, _X, _y) = sess.run((b,W,X,y), feed_dict={X:X_ary})\n",
    "    \n",
    "    print('b:'); print(_b)\n",
    "    print('W:'); print(_W)\n",
    "    print('X:'); print(_X)\n",
    "    print('y:'); print(_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b:\n",
      "[[0.7949823  0.06267278]]\n",
      "W:\n",
      "[[-0.4488959   0.5131567 ]\n",
      " [ 0.68561244 -1.078967  ]\n",
      " [-1.3305454   0.4267944 ]]\n",
      "X:\n",
      "[[ 0.4  0.2  0.4]\n",
      " [ 0.3  0.4  0.5]\n",
      " [ 0.3 -0.4  0.5]]\n",
      "y:\n",
      "[[0.5548603  0.55548555]\n",
      " [0.5669176  0.4996075 ]\n",
      " [0.4306489  0.70299566]]\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(tf.random_normal([3, 2]))\n",
    "b = tf.Variable(tf.random_normal([1, 2]))\n",
    "X = tf.placeholder(\"float\", [None, 3])\n",
    "\n",
    "y = tf.nn.sigmoid(tf.matmul(X,W)+b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    X_ary = np.array([[0.4,  0.2, 0.4],\n",
    "                      [0.3,  0.4, 0.5],\n",
    "                      [0.3, -0.4, 0.5]])\n",
    "    (_b, _W, _X, _y) = sess.run((b,W,X,y), feed_dict={X:X_ary})\n",
    "    \n",
    "    print('b:'); print(_b)\n",
    "    print('W:'); print(_W)\n",
    "    print('X:'); print(_X)\n",
    "    print('y:'); print(_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(output_dim, input_dim, inputs, activation=None):\n",
    "    W = tf.Variable(tf.random_normal([input_dim, output_dim]))\n",
    "    b = tf.Variable(tf.random_normal([1, output_dim]))\n",
    "    \n",
    "    XWb = tf.matmul(inputs, W) + b\n",
    "    \n",
    "    if activation is None:\n",
    "        outputs = XWb\n",
    "    else:\n",
    "        outputs = activation(XWb)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input  layer X:\n",
      "[[0.4 0.2 0.4 0.5]]\n",
      "hidden layer h:\n",
      "[[0. 0. 0.]]\n",
      "output layer y:\n",
      "[[0.1022853  0.73476684]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(\"float\", [None,4])\n",
    "h = layer(output_dim=3, input_dim=4, inputs=X, activation=tf.nn.relu)\n",
    "y = layer(output_dim=2, input_dim=3, inputs=h)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    X_array = np.array([[0.4, 0.2, 0.4, 0.5]])\n",
    "    (layer_X, layer_h, layer_y) = sess.run((X,h,y), feed_dict={X:X_array})\n",
    "    \n",
    "    print('input  layer X:'); print(layer_X)\n",
    "    print('hidden layer h:'); print(layer_h)\n",
    "    print('output layer y:'); print(layer_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_debug(output_dim, input_dim, inputs, activation=None):\n",
    "    W = tf.Variable(tf.random_normal([input_dim, output_dim]))\n",
    "    b = tf.Variable(tf.random_normal([1, output_dim]))\n",
    "    \n",
    "    XWb = tf.matmul(inputs, W) + b\n",
    "    \n",
    "    if activation is None:\n",
    "        outputs = XWb\n",
    "    else:\n",
    "        outputs = activation(XWb)\n",
    "    return outputs, W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input layer X:\n",
      "[[0.4 0.2 0.4 0.5]]\n",
      "W1:\n",
      "[[ 0.27653268 -0.42200932 -0.2140344 ]\n",
      " [-1.4634157  -0.1363069   0.74464214]\n",
      " [-0.2515128  -0.33848473 -0.7304316 ]\n",
      " [ 0.5161398  -0.21063884 -1.4346143 ]]\n",
      "b1:\n",
      "[[ 1.8385392  -1.0170711  -0.01781334]]\n",
      "\n",
      "hidden layer h:\n",
      "[[1.813934 0.       0.      ]]\n",
      "W2\n",
      "[[-0.29550964  0.6202708 ]\n",
      " [ 0.06516044  3.7358756 ]\n",
      " [ 0.36764905  0.03083463]]\n",
      "b2\n",
      "[[-0.01386163  0.79767567]]\n",
      "\n",
      "output layer y:\n",
      "[[-0.54989654  1.922806  ]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(\"float\", [None,4])\n",
    "h, W1, b1 = layer_debug(output_dim=3, input_dim=4, inputs=X, activation=tf.nn.relu)\n",
    "y, W2, b2 = layer_debug(output_dim=2, input_dim=3, inputs=h)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    X_array = np.array([[0.4, 0.2, 0.4, 0.5]])\n",
    "    (layer_X, layer_h, layer_y, W1, b1, W2, b2) = \\\n",
    "      sess.run((X,h,y,W1,b1,W2,b2), feed_dict={X:X_array})\n",
    "    \n",
    "    print('input layer X:'); print(layer_X)\n",
    "    print('W1:'); print(W1)\n",
    "    print('b1:'); print(b1)\n",
    "    print('\\nhidden layer h:'); print(layer_h)\n",
    "    print('W2'); print(W2)\n",
    "    print('b2'); print(b2)\n",
    "    print('\\noutput layer y:'); print(layer_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
